{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b86104",
   "metadata": {},
   "source": [
    "# 11.5.1 Performing an Automated Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b2d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Your Code to Use Your Tools\n",
    "# In this section, you’ll set up your web scraping code to be able to use the tools that you’ll need.\n",
    "\n",
    "# To begin, complete the following steps:\n",
    "\n",
    "# Create a new folder, and then use the terminal to navigate to it.\n",
    "\n",
    "# Activate Jupyter Notebook.\n",
    "\n",
    "# Create a new Practice.ipynb file.\n",
    "# DevTools to inspect a website and using Beautiful Soup to parse HTML code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb9d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, in the first cell of Practice.ipynb, enter the following code:\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next cell, set the executable path and initialize a browser by entering the following code:\n",
    "\n",
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72bd7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the Title\n",
    "# At last, we can scrape the \"Top Ten tags\" title. To begin, in the next cell in your Jupyter notebook, enter and run the following code:\n",
    "\n",
    "# Visit the Quotes to Scrape site\n",
    "\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef08c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've now parsed all the HTML code on the page. This means that Beautiful Soup has examined the components on the page and can access them. Specifically, Beautiful Soup has parsed the HTML text and stored it as an object.\n",
    "\n",
    "# In the preceding code, we use html.parser to parse the information, but other options also exist.\n",
    "\n",
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0ca28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>Top Ten tags</h2>\n",
      "Top Ten tags\n"
     ]
    }
   ],
   "source": [
    "# Next, we want to find the title and extract it. To do so, in the next cell, enter and run the following code:\n",
    "\n",
    "# Scrape the Title\n",
    "\n",
    "h2 = html_soup.find('h2')\n",
    "title = h2.text\n",
    "print(h2)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d64b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the preceding code, the first print statement displays <h2>Top Ten tags</h2>. And, the second print statement displays Top Ten tags. To understand how we got those, let’s go over the first two lines of code:\n",
    "\n",
    "# On the h2 = html_soup.find('h2') line, we use the html_soup object that we created earlier and call its find method to search for the <h2 /> tag. Printing the result thus produces <h2>Top Ten tags</h2>.\n",
    "\n",
    "# On the title = h2.text line, we extract just the text from the <h2 /> tag by adding .text to the end of the code. This extracts the text attribute, so printing it produces only the title text of Top Ten tags.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec55289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also directly access the title text by using\n",
    "\n",
    "title = html_soup.find('h2').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c98dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the opening tag for this division is <div class=\"col-md-4 tags-box\">. This means that this division has two classes: col-md-4 and tags-box.\n",
    "\n",
    "# An HTML element can belong to multiple classes.\n",
    "\n",
    "# he col-md-4 class is a Bootstrap feature. Bootstrap is an HTML and CSS library that simplifies building websites. It uses a grid system to divide a page into 12 columns of equal width. In this case, col-md-4 means that the box containing “Top Ten tags” takes up four columns. The main quotes section takes up the remaining eight columns. Websites that use Bootstrap commonly use this class, but many others exist.\n",
    "\n",
    "# The other class, tags-box, seems specific to this website, but we want to confirm that. To do so, use the DevTools Find box to search for it.\n",
    "\n",
    "# Notice that searching for “tags-box” returns only one result: our <div class=\"col-md-4 tags-box\"> tag. This means that tags-box is unique in the HTML code, so we can use it to find specific data.\n",
    "\n",
    "# Next, we want to examine the content of this div element. To do so, in DevTools, expand the <div class=\"col-md-4 tags-box\"> line.\n",
    "\n",
    "# Notice that we get the <h2>Top Ten tags</h2> line followed by a list of <span /> tags, each with a class of tag-item. Expand some of the span elements to review their contents. If you observe <a /> tags that contain the names of the Top Ten tags, you're in the right place.\n",
    "\n",
    "# Because the list that displays on the webpage contains 10 items, let's use the DevTools search function to verify the list item count. This is one more way to check that we’ll scrape the correct data. To do so, search for “tag-item” (without the quotation marks), and then note the number of returned results. This number should indeed be 11.\n",
    "\n",
    "# Use the DevTools Find box to verify the number of instances of an element\n",
    "\n",
    "# Splendid! We can now scrape all the tags by using a for loop. To do so, in the next cell of your notebook, enter and run the following code:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83582d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "inspirational\n",
      "life\n",
      "humor\n",
      "books\n",
      "reading\n",
      "friendship\n",
      "friends\n",
      "truth\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "# Scrape the top ten tags\n",
    "\n",
    "tag_box = html_soup.find('div', class_='tags-box')\n",
    "\n",
    "# tag_box\n",
    "tags = tag_box.find_all('a', class_='tag')\n",
    "\n",
    "for tag in tags:\n",
    "    word = tag.text\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d470143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go over the preceding code:\n",
    "\n",
    "# The first line, tag_box = html_soup.find('div', class_='tags-box'), assigns the results of a search to a new variable named tag_box. The search is for <div /> tags that have a class of tags-box.\n",
    "\n",
    "# This search occurs in the HTML code that we parsed and stored in the html_soup variable earlier.\n",
    "\n",
    "# The class_ argument contains an underscore (_). That’s because the word class is reserved for other uses in Python..\n",
    "\n",
    "# The second line, tags = tag_box.find_all('a', class_='tag'), drills down further into the data in tag_box.\n",
    "\n",
    "# This line uses the find_all method to search within tag_box. This time, we search through the parsed results that are stored in our tag_box variable to find all the anchor (a) elements that belong to the tag class.\n",
    "\n",
    "# We use find_all because we want to capture all the results rather than a single or specific one.\n",
    "\n",
    "# The Beautiful Soup find method returns the first search result. The find_all method returns all the results.\n",
    "\n",
    "# We added a for loop. This loop cycles through the tags in the tags variable, extracts the HTML code from each, and then prints only the text of each tag.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "023ba3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86031a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c8694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef2fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6900ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac739e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9c735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedadbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18126e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fe15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ad8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
